{
  "2026-01-01": "1. **Generate Synthetic Time Series Data**: Create a pandas DataFrame `df` with 800 daily entries. It should have a `date` column (daily dates starting from '2023-01-01') and a `sales_amount` column. Populate `sales_amount` with a synthetic time series, for example, a combination of a linear trend, a yearly seasonality (using `np.sin`), and some random noise (using `np.random.normal`).\n2. **Feature Engineering - Lag Features**: Create two new features in the DataFrame: `sales_amount_lag_1` (representing the sales from the previous day) and `sales_amount_lag_7` (representing sales from 7 days prior) using pandas' `shift()` method.\n3. **Feature Engineering - Rolling Statistics**: Create two more new features: `rolling_mean_3_days` (a 3-day rolling mean of `sales_amount`) and `rolling_std_7_days` (a 7-day rolling standard deviation of `sales_amount`) using pandas' `rolling()` method. Ensure you handle potential `NaN` values from rolling operations (e.g., `min_periods=1` if you want to keep early rows, or simply let `NaN`s propagate and drop later).\n4. **Handle Missing Values and Prepare for Modeling**: After creating all engineered features, drop any rows that contain `NaN` values (which will typically appear at the beginning of the DataFrame due to `shift` and `rolling` operations). Then, define the target variable `y` as the `sales_amount` column of the processed DataFrame, and the features `X` as all the engineered lag and rolling features. Display the head of the final `X` and `y` DataFrames to show the prepared dataset.\n5. **Visualize Feature-Target Relationship**: Pick one of the engineered features (e.g., `sales_amount_lag_1`) and plot its relationship with the `sales_amount` target using a `seaborn.lineplot` or `seaborn.scatterplot`. Ensure the plot has appropriate labels and a title.",
  "2026-01-02": "1. Generate a synthetic binary classification dataset using `sklearn.datasets.make_classification` with at least 1500 samples, 8 features (e.g., `n_informative=6`), and 2 classes (set `random_state` for reproducibility).\n2. Split the dataset into training and testing sets (e.g., 70/30 split) using `sklearn.model_selection.train_test_split`.\n3. Create two distinct `sklearn.pipeline.Pipeline` objects for classification:\n    *   `pipeline_lr`: Consisting of `StandardScaler` followed by `LogisticRegression` (set `random_state=42`, `solver='liblinear'`).\n    *   `pipeline_gb`: Consisting of `StandardScaler` followed by `GradientBoostingClassifier` (set `random_state=42`).\n4. For each pipeline, define a small, focused hyperparameter grid for `sklearn.model_selection.GridSearchCV`:\n    *   For `pipeline_lr`: Tune `C` (e.g., `[0.1, 1, 10]`).\n    *   For `pipeline_gb`: Tune `n_estimators` (e.g., `[50, 100]`) and `learning_rate` (e.g., `[0.05, 0.1]`).\n5. Perform `GridSearchCV` *separately* for `pipeline_lr` and `pipeline_gb` on the training data. Use 3-fold cross-validation and `scoring='roc_auc'` for both. (Set `n_jobs=-1` for faster execution).\n6. Report the `best_params_` and `best_score_` (ROC AUC) for each model (Logistic Regression and Gradient Boosting Classifier).\n7. Using the *best estimators* obtained from `GridSearchCV` for both models, predict probabilities for the positive class (class 1) on the test set.\n8. Plot the Receiver Operating Characteristic (ROC) curve for *both* models on the *same* plot using `sklearn.metrics.RocCurveDisplay.from_estimator` (or `from_predictions` if preferred). Ensure the plot has a clear title, a legend indicating which curve belongs to which model, and displays the AUC score for each model."
}