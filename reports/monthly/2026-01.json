{
  "2026-01-01": "1. **Generate Synthetic Time Series Data**: Create a pandas DataFrame `df` with 800 daily entries. It should have a `date` column (daily dates starting from '2023-01-01') and a `sales_amount` column. Populate `sales_amount` with a synthetic time series, for example, a combination of a linear trend, a yearly seasonality (using `np.sin`), and some random noise (using `np.random.normal`).\n2. **Feature Engineering - Lag Features**: Create two new features in the DataFrame: `sales_amount_lag_1` (representing the sales from the previous day) and `sales_amount_lag_7` (representing sales from 7 days prior) using pandas' `shift()` method.\n3. **Feature Engineering - Rolling Statistics**: Create two more new features: `rolling_mean_3_days` (a 3-day rolling mean of `sales_amount`) and `rolling_std_7_days` (a 7-day rolling standard deviation of `sales_amount`) using pandas' `rolling()` method. Ensure you handle potential `NaN` values from rolling operations (e.g., `min_periods=1` if you want to keep early rows, or simply let `NaN`s propagate and drop later).\n4. **Handle Missing Values and Prepare for Modeling**: After creating all engineered features, drop any rows that contain `NaN` values (which will typically appear at the beginning of the DataFrame due to `shift` and `rolling` operations). Then, define the target variable `y` as the `sales_amount` column of the processed DataFrame, and the features `X` as all the engineered lag and rolling features. Display the head of the final `X` and `y` DataFrames to show the prepared dataset.\n5. **Visualize Feature-Target Relationship**: Pick one of the engineered features (e.g., `sales_amount_lag_1`) and plot its relationship with the `sales_amount` target using a `seaborn.lineplot` or `seaborn.scatterplot`. Ensure the plot has appropriate labels and a title.",
  "2026-01-02": "1. Generate a synthetic binary classification dataset using `sklearn.datasets.make_classification` with at least 1500 samples, 8 features (e.g., `n_informative=6`), and 2 classes (set `random_state` for reproducibility).\n2. Split the dataset into training and testing sets (e.g., 70/30 split) using `sklearn.model_selection.train_test_split`.\n3. Create two distinct `sklearn.pipeline.Pipeline` objects for classification:\n    *   `pipeline_lr`: Consisting of `StandardScaler` followed by `LogisticRegression` (set `random_state=42`, `solver='liblinear'`).\n    *   `pipeline_gb`: Consisting of `StandardScaler` followed by `GradientBoostingClassifier` (set `random_state=42`).\n4. For each pipeline, define a small, focused hyperparameter grid for `sklearn.model_selection.GridSearchCV`:\n    *   For `pipeline_lr`: Tune `C` (e.g., `[0.1, 1, 10]`).\n    *   For `pipeline_gb`: Tune `n_estimators` (e.g., `[50, 100]`) and `learning_rate` (e.g., `[0.05, 0.1]`).\n5. Perform `GridSearchCV` *separately* for `pipeline_lr` and `pipeline_gb` on the training data. Use 3-fold cross-validation and `scoring='roc_auc'` for both. (Set `n_jobs=-1` for faster execution).\n6. Report the `best_params_` and `best_score_` (ROC AUC) for each model (Logistic Regression and Gradient Boosting Classifier).\n7. Using the *best estimators* obtained from `GridSearchCV` for both models, predict probabilities for the positive class (class 1) on the test set.\n8. Plot the Receiver Operating Characteristic (ROC) curve for *both* models on the *same* plot using `sklearn.metrics.RocCurveDisplay.from_estimator` (or `from_predictions` if preferred). Ensure the plot has a clear title, a legend indicating which curve belongs to which model, and displays the AUC score for each model.",
  "2026-01-03": "1. Generate a synthetic binary classification dataset using `sklearn.datasets.make_classification` with at least 1000 samples, 4 informative features, and 2 classes (set `random_state` for reproducibility).\n2. Split the dataset into training and testing sets (e.g., 70/30 split) using `sklearn.model_selection.train_test_split`.\n3. Standardize the features using `sklearn.preprocessing.StandardScaler` on the training data, then transform both training and testing sets.\n4. Build a simple sequential neural network model using `tensorflow.keras.models.Sequential` for binary classification. The model should have:\n    *   An input layer matching the number of features.\n    *   One hidden `Dense` layer with `relu` activation (e.g., 16-32 units).\n    *   An output `Dense` layer with a single unit and `sigmoid` activation.\n5. Compile the model using the `adam` optimizer and `binary_crossentropy` loss.\n6. Train the model on the scaled training data for a suitable number of epochs (e.g., 30-50) and a batch size.\n7. Predict probabilities on the scaled test set. Convert these probabilities to binary class labels (0 or 1) using a threshold (e.g., 0.5).\n8. Print the `sklearn.metrics.classification_report` for the test set predictions.\n9. Generate and plot a confusion matrix using `sklearn.metrics.ConfusionMatrixDisplay.from_predictions` for the test set, clearly labeling the plot with a title (e.g., 'Confusion Matrix for Keras Binary Classifier').",
  "2026-01-04": "1. Generate a synthetic binary classification dataset using `sklearn.datasets.make_classification` with at least 1000 samples, 5 informative features, and 2 classes (set `random_state` for reproducibility).\n2. Split the dataset into training and testing sets (e.g., 70/30 split) using `sklearn.model_selection.train_test_split`.\n3. Define a function `create_keras_model(optimizer='adam', units=32)` that builds and compiles a `tensorflow.keras.models.Sequential` model. This model should have an input layer matching the number of features, one `Dense` hidden layer with `relu` activation (using `units` as a parameter), and a `Dense` output layer with `sigmoid` activation. Compile it with `binary_crossentropy` loss.\n4. Wrap this Keras model using `tensorflow.keras.wrappers.scikit_learn.KerasClassifier`.\n5. Construct an `sklearn.pipeline.Pipeline` that first applies `sklearn.preprocessing.StandardScaler` and then uses the wrapped `KerasClassifier`.\n6. Define a hyperparameter grid for `sklearn.model_selection.GridSearchCV` to tune the following parameters of the Keras model within the pipeline:\n    *   `kerasclassifier__batch_size` (e.g., `[32, 64]`)\n    *   `kerasclassifier__epochs` (e.g., `[10, 20]`)\n    *   `kerasclassifier__model__units` (e.g., `[16, 32]`)\n    *   `kerasclassifier__optimizer` (e.g., `['adam', 'rmsprop']`)\n7. Perform `GridSearchCV` with 3-fold cross-validation and `scoring='roc_auc'` on the training data. (Set `n_jobs=-1` for faster execution).\n8. Report the `best_params_` and `best_score_` from `GridSearchCV`. Then, using the `best_estimator_`, predict class labels on the test set and print the `sklearn.metrics.classification_report`."
}