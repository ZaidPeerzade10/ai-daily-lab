{
  "task": "1. Generate a synthetic regression dataset using `sklearn.datasets.make_regression` with 1000 samples, 3 informative features. Modify the target `y` to introduce a non-linear relationship (e.g., `y_original + 2 * X[:, 0]**2 + np.random.normal(0, 0.5, size=1000)`).\n2. Split the dataset into training and testing sets (e.g., 80/20 split) using `sklearn.model_selection.train_test_split`.\n3. Apply `sklearn.preprocessing.StandardScaler` to the features (`X`) on the training data and transform both training and testing sets.\n4. Build a simple sequential neural network model using `tensorflow.keras.models.Sequential`. The model should have:\n    *   An input layer matching the number of features.\n    *   At least one hidden `Dense` layer with `relu` activation (e.g., 32 units).\n    *   An output `Dense` layer with a single unit and linear activation.\n5. Compile the model using the `adam` optimizer and `mean_squared_error` loss.\n6. Train the model on the scaled training data for a suitable number of epochs (e.g., 50-100) and a batch size.\n7. Evaluate the trained model's performance on the scaled test set, reporting the Mean Squared Error (MSE).\n8. Visualize the model's predictions against the actual test target values using a scatter plot. Add a perfect prediction line (y=x) for comparison and label axes appropriately.",
  "focus": "basic AI experimentation",
  "dataset": "Synthetic regression data with a non-linear component",
  "hint": "Remember to import `tensorflow.keras` for model building and `sklearn.preprocessing.StandardScaler` for data preparation. The `y=x` line helps visually assess model bias and variance.",
  "date": "2025-12-30",
  "timestamp": "2025-12-30T04:32:42.321743Z"
}