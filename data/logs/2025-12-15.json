{
  "task": "1. Generate a synthetic regression dataset using `sklearn.datasets.make_regression` with 1000 samples, 5 informative features, and a small amount of noise. Additionally, generate 5 completely random, uninformative features (e.g., using `np.random.rand`) and concatenate them to your original features, creating a feature matrix `X` with 10 features.\n2. Create an `sklearn.pipeline.Pipeline` that first applies `StandardScaler`, then uses `sklearn.feature_selection.SelectKBest` (with `f_regression` as the score function) for feature selection, and finally fits a `LinearRegression` model.\n3. Define a hyperparameter grid for `sklearn.model_selection.GridSearchCV` to tune the `k` parameter of `SelectKBest` (e.g., `[3, 5, 7, 10]` to explore different numbers of selected features).\n4. Use `GridSearchCV` with the pipeline and the defined parameter grid. Perform 3-fold cross-validation and use `neg_mean_squared_error` as the scoring metric.\n5. Report the best `k` value found, the corresponding best cross-validation score (converting `neg_mean_squared_error` to positive MSE), and the indices of the features selected by the best model (you might need to extract the `SelectKBest` step from the best estimator).",
  "focus": "Feature Selection, ML Pipelines, Hyperparameter Tuning, Regression",
  "dataset": "Synthetic regression data (`make_regression`) augmented with random noise features.",
  "hint": "When setting up `SelectKBest` in the pipeline, remember to specify the score function (`f_regression`). For `GridSearchCV`, the parameter for `SelectKBest` will be `selectkbest__k` (lowercase and double underscore) in the `param_grid`. To get the selected features from the best estimator, you can access `best_estimator_.named_steps['selectkbest'].get_support(indices=True)`.",
  "date": "2025-12-15",
  "timestamp": "2025-12-15T04:33:38.474439Z"
}