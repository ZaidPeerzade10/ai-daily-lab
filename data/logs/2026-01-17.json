{
  "task": "1. **Generate Synthetic Transactional Data**: Create a pandas DataFrame `transactions_df` with 800-1000 rows. Columns should include:\n    *   `transaction_id` (unique integers)\n    *   `transaction_date` (daily dates spanning 2-3 years, starting from '2022-01-01')\n    *   `product_category` (e.g., 4-5 distinct string categories like 'Electronics', 'Books', 'Groceries', 'Clothing', but with inconsistent casing and minor variations, e.g., 'electronics', 'Book', 'groceries item', 'clothes').\n    *   `description` (short text descriptions that sometimes contain keywords like 'discount', 'premium', 'sale').\n    *   `amount` (random float values between 10.0 and 500.0).\n    Ensure the DataFrame is sorted by `product_category` and then `transaction_date`.\n2. **Advanced Feature Engineering**: \n    *   **Clean Categorical**: Create a new column `clean_category` by standardizing the `product_category` names (e.g., 'electronics', 'Electronics', 'ELEC' all map to 'Electronics').\n    *   **Datetime Features**: Extract `month` and `day_of_week` (integer 0-6) from `transaction_date`.\n    *   **Text Feature**: Create `is_discount` (binary: 1 if 'discount' or 'sale' is found in `description` case-insensitively, 0 otherwise).\n    *   **Grouped Lag Feature**: For each `clean_category`, calculate `lagged_amount_1d`, which is the `amount` from the previous day for that *specific category*. Fill `NaN` values (e.g., with 0, or by propagating the last valid observation forward and then filling remaining with 0 if needed for initial values).\n3. **Chronological Data Split**: Define features `X` (all engineered features created in step 2) and target `y` (the original `amount` column). Split the data chronologically, using the last 60 days of data for the test set. Ensure `X_train`, `X_test`, `y_train`, `y_test` are correctly defined.\n4. **ML Pipeline with ColumnTransformer**: Create an `sklearn.pipeline.Pipeline` that uses `sklearn.compose.ColumnTransformer` for preprocessing and `sklearn.ensemble.RandomForestRegressor` as the final estimator (set `random_state=42`, `n_estimators=100`).\n    *   **Inside the `ColumnTransformer`**:\n        *   For numerical features (`lagged_amount_1d`): Apply `SimpleImputer(strategy='mean')` followed by `StandardScaler`.\n        *   For categorical features (`clean_category`, `month`, `day_of_week`): Apply `OneHotEncoder(handle_unknown='ignore')`.\n        *   For the binary feature (`is_discount`): Use `Passthrough`.\n5. **Train, Predict, and Evaluate**: Train the pipeline on the training data (`X_train`, `y_train`). Predict `amount` for the test set (`X_test`). Calculate and report the `sklearn.metrics.mean_absolute_error` (MAE) and `sklearn.metrics.r2_score`.\n6. **Visualize Forecast**: Create a single line plot showing the actual `amount` values for the test period and the model's predicted `amount` values for the same period. Label the axes, add a title like 'Actual vs. Predicted Amounts for Test Set', and include a legend.",
  "focus": "Feature Engineering (datetime, string, grouped lags), ML Pipelines (ColumnTransformer), Regression, Model Evaluation, Data Visualization",
  "dataset": "Synthetic transactional data with date, category, description, and amount.",
  "hint": "Pay close attention to sorting before calculating grouped lag features. For the ColumnTransformer, ensure you correctly map feature names to their respective transformers and remember that `amount` itself is the target `y`, not a feature in `X`.",
  "date": "2026-01-17",
  "timestamp": "2026-01-17T04:26:20.847914Z"
}